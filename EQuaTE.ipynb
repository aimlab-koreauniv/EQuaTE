{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f8ace-6141-4ccc-abb9-a9e57bf5fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchquantum as tq\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from torchquantum.encoding import encoder_op_list_name_dict\n",
    "from torchquantum.layers import U3CU3Layer0, RandomLayer\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torchquantum.encoding import encoder_op_list_name_dict as enc_dict\n",
    "from torchquantum.layers import U3CU3Layer0 \n",
    "from models import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "num_client  = 10\n",
    "\n",
    "num_class = 4\n",
    "EPOCH = 100\n",
    "TrainLoader = DataLoader(Dataset(np.load('data/mnist/train_x.npy')[:18623],np.load('data/mnist/train_y.npy')[:18623],0),batch_size=256,shuffle=True)\n",
    "\n",
    "Data = []\n",
    "Labels = []\n",
    "for i, (data, labels) in enumerate(TrainLoader):\n",
    "    Data.append(data)\n",
    "    Labels.append(labels)\n",
    "    if i==2:\n",
    "        break\n",
    "        \n",
    "TrainLoader = DataLoader(Dataset(Data[0],Labels[0],0),batch_size=32,shuffle=True)\n",
    "TestLoader  = DataLoader(Dataset(Data[1],Labels[1],0),batch_size=32,shuffle=True)\n",
    "ValidLoader = DataLoader(Dataset(Data[2][:32],Labels[2][:32],0), batch_size=1, shuffle=True)\n",
    "device = torch.device('cuda:0')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "q_device = tq.QuantumDevice(n_wires=4).to(device)\n",
    "\n",
    "class QNN(tq.QuantumModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_wires = 4\n",
    "        self.encoder = tq.GeneralEncoder(enc_dict['4x4_ryzxy'])\n",
    "        self.pqc     = tq.RandomLayer(n_ops=50, wires=[0,1,2,3])\n",
    "        \n",
    "    def forward(self, x,q_device=q_device):\n",
    "        batchsize = x.shape[0]\n",
    "        x = x.reshape(batchsize,-1).to(dtype=torch.complex64)\n",
    "        self.encoder(q_device , x)\n",
    "        self.pqc(q_device)\n",
    "        x = tq.expval(q_device,\n",
    "                      [i for i in range(num_class)], \n",
    "                      [tq.PauliZ() for _ in range(num_class)]\n",
    "                     ).squeeze() \n",
    "        return x\n",
    "    \n",
    "model = QNN().to(device)\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime(\"%m%d%H%M%S\")\n",
    "# writer = SummaryWriter(f'runs/{today}')\n",
    "writer = SummaryWriter(f'ICSE_2023')\n",
    "def train(ep,\n",
    "          train_loader,\n",
    "          test_loader,\n",
    "          valid_loader, \n",
    "          model, \n",
    "          device, \n",
    "          criterion,\n",
    "          optimizer):\n",
    "    \n",
    "    Train_Loss = 0 \n",
    "    Test_Acc   = 0\n",
    "    # Train #\n",
    "    for niter, (data, labels) in enumerate(train_loader):\n",
    "        inputs  = data.to(device,dtype=torch.float32)\n",
    "        targets = labels.to(device,dtype=torch.long)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss    = criterion(torch.softmax(outputs,dim=-1), targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Train_Loss = loss.item()\n",
    "        \n",
    "    # Test #\n",
    "    with torch.no_grad():\n",
    "        Size = 0\n",
    "        Corrects = 0\n",
    "        for _, (x,y) in enumerate(test_loader):\n",
    "            x = x.to(device,dtype=torch.float32)\n",
    "            y = y.to(device,dtype=torch.long)\n",
    "            y_hat = model(x) \n",
    "            _, indices = y_hat.topk(1, dim=1)\n",
    "            masks = indices.eq(y.view(-1, 1).expand_as(indices))\n",
    "            Size += y.shape[0]\n",
    "            Corrects += masks.sum().item()\n",
    "        Test_Acc = Corrects / Size\n",
    "            \n",
    "    # Barren Plateaus # \n",
    "    grad_bp,mean, var = {},{},{}\n",
    "    \n",
    "    for i,(name, params) in enumerate(model.pqc.named_parameters()):\n",
    "        grad_bp[name] = []\n",
    "    \n",
    "    for niter, (data, labels) in enumerate(valid_loader):\n",
    "        inputs  = data.to(device,dtype=torch.float32)\n",
    "        targets = labels.to(device,dtype=torch.long)\n",
    "        outputs = model(inputs)\n",
    "        loss    = criterion(torch.softmax(outputs,dim=-1).unsqueeze(0), targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for i, (name, params) in enumerate(model.pqc.named_parameters()):\n",
    "            grad_bp[name].append(params.grad.clone().detach().cpu().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if niter==31:\n",
    "            break\n",
    "\n",
    "    \n",
    "    for key in grad_bp.keys():\n",
    "        grads     = grad_bp[key]\n",
    "        grads     = np.array(grads)\n",
    "        mean[key] = np.mean(grads)\n",
    "        var[key]  = np.var(grads)\n",
    "    \n",
    "    return Train_Loss, Test_Acc, var\n",
    "\n",
    "def Helper(ep,var):\n",
    "    Event = []\n",
    "    for key in  var.keys():\n",
    "        gate  = key.split('.')[2].split('_params')[0]\n",
    "        order = int(key.split('.')[1]) + 1\n",
    "        bp_value = var[key]\n",
    "        if bp_value <= 1e-5:\n",
    "            event = f\"[Epoch {ep}] {order}-th params ({gate} Gate) has barren plateaus (BP value: {var[key]})\"\n",
    "            Event.append(event)\n",
    "    return '<br>'.join(Event)\n",
    "\n",
    "for ep in range(EPOCH):\n",
    "    Train_Loss, Test_Acc, var = train(  ep, \n",
    "                                        TrainLoader, \n",
    "                                        TestLoader, \n",
    "                                        ValidLoader,  \n",
    "                                        model,  \n",
    "                                        device,  \n",
    "                                        criterion, \n",
    "                                        opt\n",
    "                                     )\n",
    "    \n",
    "    writer.add_scalars(f'Metric/Loss', {'loss': Train_Loss} ,ep+1)\n",
    "    writer.add_scalars(f'Metric/Accuracy', {'acc': Test_Acc} ,ep+1)\n",
    "    writer.add_scalars(f'Metric/BarrenPlateaus', var,ep+1)\n",
    "    writer.add_text('Event',Helper(ep+1,var), ep+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fed1df-bddc-4d31-bc90-2388f2bdbe93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
